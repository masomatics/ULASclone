{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload\n",
    "from datasets.three_dim_shapes import ThreeDimShapesDataset\n",
    "from datasets.small_norb import SmallNORBDataset\n",
    "from datasets.seq_mnist import SequentialMNIST\n",
    "import models.seqae as seqae\n",
    "import signal\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    gpu_index = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH TO THE ROOT OF DATASETS DIRECTORIES\n",
    "datadir = '/tmp/path/to/datadir'\n",
    "logdir = '/tmp/path/to/logdir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivariance error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, log_dir, iters):\n",
    "    model.load_state_dict(torch.load(os.path.join(\n",
    "        log_dir, 'snapshot_model_iter_{}'.format(iters)), map_location=device))\n",
    "\n",
    "n_cond = 2\n",
    "\n",
    "shared_transition = True\n",
    "equiv_errors = {}\n",
    "dataset_names = ['mnist', 'mnist_bg', '3dshapes', 'smallNORB']\n",
    "model_names = ['neuralM', 'lstsq_rec', 'lstsq']\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    equiv_errors[dataset_name] = {}\n",
    "    rng = np.random.RandomState(1)\n",
    "    if dataset_name == 'mnist':\n",
    "        T = 10\n",
    "        test_data = SequentialMNIST(\n",
    "            datadir, False, T=T, max_angle_velocity_ratio=[-0.2, 0.2],\n",
    "            max_color_velocity_ratio=[-0.2, 0.2],\n",
    "            max_pos=[-10, 10],\n",
    "            max_T=T,\n",
    "            only_use_digit4=True,\n",
    "            backgrnd=False,\n",
    "            rng=rng)\n",
    "        bottom_width = 4\n",
    "        n_blocks = 3\n",
    "        k = 2\n",
    "        ch_x = 3\n",
    "        iters=50000\n",
    "    elif dataset_name == 'mnist_bg':\n",
    "        T = 10\n",
    "        test_data = SequentialMNIST(\n",
    "            datadir, False, T=T, max_angle_velocity_ratio=[-0.2, 0.2],\n",
    "            max_color_velocity_ratio=[-0.2, 0.2],\n",
    "            max_pos=[-10, 10],\n",
    "            max_T=T,\n",
    "            only_use_digit4=True,\n",
    "            backgrnd=True,\n",
    "            rng=rng)\n",
    "        bottom_width = 4\n",
    "        n_blocks = 3\n",
    "        k = 4\n",
    "        ch_x = 3  \n",
    "        iters=100000\n",
    "    elif dataset_name == '3dshapes':\n",
    "        T = 8\n",
    "        test_data = ThreeDimShapesDataset(\n",
    "            root=datadir,\n",
    "            train=True, T=T,\n",
    "            rng=rng)\n",
    "        bottom_width = 8\n",
    "        n_blocks = 3\n",
    "        k=1\n",
    "        ch_x = 3\n",
    "        iters=50000\n",
    "    elif dataset_name == 'smallNORB':\n",
    "        T = 6\n",
    "        test_data = SmallNORBDataset(\n",
    "            root=datadir,\n",
    "            train=False,\n",
    "            T=T,\n",
    "            rng=rng)\n",
    "        bottom_width = 6\n",
    "        n_blocks = 4\n",
    "        k=1\n",
    "        ch_x = 1\n",
    "        iters=50000\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    n_rolls = T - n_cond\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        if model_name == 'neural_trans':\n",
    "            model = seqae.SeqAENeuralTransition(\n",
    "                dim_a=16, dim_m=256, global_average_pooling=False, k=k, T_cond=2, bottom_width=bottom_width, n_blocks=n_blocks, ch_x=ch_x)\n",
    "        elif model_name == 'neuralM':\n",
    "            model = seqae.SeqAENeuralM(\n",
    "                dim_a=16, dim_m=256, global_average_pooling=False, k=k, bottom_width=bottom_width, n_blocks=n_blocks, ch_x=ch_x)\n",
    "        elif model_name == 'multi-lstsq_K8':\n",
    "            model = seqae.SeqAEMultiLSTSQ(\n",
    "                dim_a=16, dim_m=256, global_average_pooling=False, k=k, K=8, bottom_width=bottom_width, n_blocks=n_blocks, ch_x=ch_x)\n",
    "        elif model_name == 'lstsq' or model_name == 'lstsq_rec':\n",
    "            model = seqae.SeqAELSTSQ(\n",
    "                dim_a=16, dim_m=256, global_average_pooling=False, k=k, bottom_width=bottom_width, n_blocks=n_blocks, ch_x=ch_x)\n",
    "        model.to(device)\n",
    "        bsize = 32\n",
    "        test_loader = DataLoader(test_data, bsize, True, num_workers=0)\n",
    "        \n",
    "        # Initialize lazy modules\n",
    "        images = iter(test_loader).next()\n",
    "        images = torch.stack(images).transpose(1, 0)\n",
    "        images = images.to(device)\n",
    "        model(images[:, :2])\n",
    "        results = []\n",
    "        for seed in [1, 2, 3]: \n",
    "            path = os.path.join(logdir, \"{}-{}-seed{}\".format(dataset_name, model_name, seed))\n",
    "            load_model(model, path, iters=iters)\n",
    "            count =0\n",
    "            losses = []\n",
    "            losses_perm = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images in tqdm(test_loader):\n",
    "                    images = torch.stack(images).transpose(1,0)\n",
    "                    images = images.to(device)\n",
    "                    images_cond = images[:, :2]\n",
    "                    images_target = images[:, 2:3]\n",
    "                    M = model.get_M(images_cond) #n a a\n",
    "                    H = model.encode(images_cond[:, -1:])[:, 0] # n s a\n",
    "                    H_next = H @ M \n",
    "                    swapM = M[torch.arange(-bsize//2, M.shape[0]-bsize//2)]\n",
    "                    H_next_perm = H @ swapM\n",
    "                    x_next = torch.sigmoid(model.decode(H_next[:, None]))\n",
    "                    x_next_perm = torch.sigmoid(model.decode(H_next_perm[:, None]))\n",
    "                    \n",
    "                    if dataset_name == 'smallNORB':\n",
    "                        x_next = torch.mean(x_next, 2, keepdims=True)\n",
    "                        x_next_perm = torch.mean(x_next_perm, 2, keepdims=True)\n",
    "                    loss = torch.sum((images_target-x_next)**2, dim=(2,3,4)).detach().cpu().numpy()\n",
    "                    loss_perm = torch.sum((images_target-x_next_perm)**2, dim=(2,3,4)).detach().cpu().numpy()\n",
    "                    losses.append(loss)\n",
    "                    losses_perm.append(loss_perm)\n",
    "                    \n",
    "                    count += 1\n",
    "                    test_data.init_shared_transition_parameters()\n",
    "            results.append([np.mean(np.concatenate(losses)), np.mean(np.concatenate(losses_perm))])\n",
    "        equiv_errors[dataset_name][model_name] = [np.mean(np.array(results), 0), np.std(np.array(results), 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(equiv_errors)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}