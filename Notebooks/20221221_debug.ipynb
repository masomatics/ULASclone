{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e745662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch \n",
    "import torch.autograd as autograd\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "with open('H0H1.pkl', 'rb') as fp:\n",
    "    problem = pickle.load(fp)\n",
    "    \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models import misc_mnet as mm\n",
    "\n",
    "Mobj = mm.Meta_Mnet(dim_a=16, batchsize=32, mode='exact')\n",
    "Mobj.Ms.data = copy.deepcopy(problem['M'])\n",
    "\n",
    "inner_args= {}\n",
    "inner_args['num_loops'] = 200\n",
    "inner_args['detach'] = 1\n",
    "\n",
    "H0 = copy.deepcopy(problem['H0'])\n",
    "H1 = copy.deepcopy(problem['H1'])\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5cbd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0280)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9665, -0.0133, -0.0074,  0.0030],\n",
       "        [-0.0232,  0.9505, -0.0124, -0.0154],\n",
       "        [-0.0015,  0.0166,  0.9546, -0.0024],\n",
       "        [ 0.0035, -0.0080,  0.0109,  0.9575]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.max(torch.abs(problem['M'])))\n",
    "\n",
    "\n",
    "Mobj.Ms[0][:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3628d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5017.1616, grad_fn=<SumBackward0>)\n",
      "tensor(70.8319, grad_fn=<SqrtBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum((H1 - H0 @ Mobj.Ms)**2))\n",
    "print(Mobj(H0, H1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b61ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner_loss 68.89547729492188\n",
      "inner_loss 68.7554702758789\n",
      "inner_loss 68.61869812011719\n",
      "inner_loss 68.48509216308594\n",
      "inner_loss 68.35458374023438\n",
      "inner_loss 68.22713470458984\n",
      "inner_loss 68.10266876220703\n",
      "inner_loss 67.98112487792969\n",
      "inner_loss 67.86245727539062\n",
      "inner_loss 67.7466049194336\n",
      "inner_loss 67.63349914550781\n",
      "inner_loss 67.5230941772461\n",
      "inner_loss 67.41533660888672\n",
      "inner_loss 67.31016540527344\n",
      "inner_loss 67.20751953125\n",
      "inner_loss 67.10736083984375\n",
      "inner_loss 67.00962829589844\n",
      "inner_loss 66.91426086425781\n",
      "inner_loss 66.82122802734375\n",
      "inner_loss 66.73046112060547\n",
      "inner_loss 66.64191436767578\n",
      "inner_loss 66.5555419921875\n",
      "inner_loss 66.47129821777344\n",
      "inner_loss 66.38912200927734\n",
      "inner_loss 66.3089828491211\n",
      "inner_loss 66.23081970214844\n",
      "inner_loss 66.15459442138672\n",
      "inner_loss 66.08026123046875\n",
      "inner_loss 66.00778198242188\n",
      "inner_loss 65.93710327148438\n",
      "inner_loss 65.86819458007812\n",
      "inner_loss 65.80101013183594\n",
      "inner_loss 65.7354965209961\n",
      "inner_loss 65.671630859375\n",
      "inner_loss 65.609375\n",
      "inner_loss 65.54867553710938\n",
      "inner_loss 65.48950958251953\n",
      "inner_loss 65.43183135986328\n",
      "inner_loss 65.37559509277344\n",
      "inner_loss 65.32079315185547\n",
      "inner_loss 65.26737213134766\n",
      "inner_loss 65.21530151367188\n",
      "inner_loss 65.16455078125\n",
      "inner_loss 65.11508178710938\n",
      "inner_loss 65.06686401367188\n",
      "inner_loss 65.01986694335938\n",
      "inner_loss 64.97406768798828\n",
      "inner_loss 64.92943572998047\n",
      "inner_loss 64.88592529296875\n",
      "inner_loss 64.8435287475586\n",
      "inner_loss 64.80220794677734\n",
      "inner_loss 64.7619400024414\n",
      "inner_loss 64.72269439697266\n",
      "inner_loss 64.68444061279297\n",
      "inner_loss 64.64717102050781\n",
      "inner_loss 64.61083984375\n",
      "inner_loss 64.575439453125\n",
      "inner_loss 64.54093933105469\n",
      "inner_loss 64.50731658935547\n",
      "inner_loss 64.47454833984375\n",
      "inner_loss 64.44261169433594\n",
      "inner_loss 64.4114990234375\n",
      "inner_loss 64.38117218017578\n",
      "inner_loss 64.35160827636719\n",
      "inner_loss 64.32280731201172\n",
      "inner_loss 64.29473876953125\n",
      "inner_loss 64.26737213134766\n",
      "inner_loss 64.24071502685547\n",
      "inner_loss 64.21472930908203\n",
      "inner_loss 64.18940734863281\n",
      "inner_loss 64.16472625732422\n",
      "inner_loss 64.14067077636719\n",
      "inner_loss 64.11722564697266\n",
      "inner_loss 64.09437561035156\n",
      "inner_loss 64.07210540771484\n",
      "inner_loss 64.05039978027344\n",
      "inner_loss 64.02925109863281\n",
      "inner_loss 64.00862884521484\n",
      "inner_loss 63.98853302001953\n",
      "inner_loss 63.96894454956055\n",
      "inner_loss 63.949851989746094\n",
      "inner_loss 63.93124008178711\n",
      "inner_loss 63.91310119628906\n",
      "inner_loss 63.895416259765625\n",
      "inner_loss 63.87818145751953\n",
      "inner_loss 63.86137771606445\n",
      "inner_loss 63.84499740600586\n",
      "inner_loss 63.82902908325195\n",
      "inner_loss 63.81346130371094\n",
      "inner_loss 63.79829025268555\n",
      "inner_loss 63.78349304199219\n",
      "inner_loss 63.76906967163086\n",
      "inner_loss 63.75501251220703\n",
      "inner_loss 63.741302490234375\n",
      "inner_loss 63.727935791015625\n",
      "inner_loss 63.71491241455078\n",
      "inner_loss 63.70220184326172\n",
      "inner_loss 63.689815521240234\n",
      "inner_loss 63.677738189697266\n",
      "inner_loss 63.665958404541016\n",
      "inner_loss 63.654476165771484\n",
      "inner_loss 63.643280029296875\n",
      "inner_loss 63.632362365722656\n",
      "inner_loss 63.62171173095703\n",
      "inner_loss 63.611328125\n",
      "inner_loss 63.60120391845703\n",
      "inner_loss 63.59132385253906\n",
      "inner_loss 63.581695556640625\n",
      "inner_loss 63.57230758666992\n",
      "inner_loss 63.563148498535156\n",
      "inner_loss 63.5542106628418\n",
      "inner_loss 63.54549789428711\n",
      "inner_loss 63.5369987487793\n",
      "inner_loss 63.528709411621094\n",
      "inner_loss 63.520626068115234\n",
      "inner_loss 63.51273727416992\n",
      "inner_loss 63.505043029785156\n",
      "inner_loss 63.49753952026367\n",
      "inner_loss 63.49021911621094\n",
      "inner_loss 63.48307800292969\n",
      "inner_loss 63.47610855102539\n",
      "inner_loss 63.46931838989258\n",
      "inner_loss 63.462684631347656\n",
      "inner_loss 63.456214904785156\n",
      "inner_loss 63.44990539550781\n",
      "inner_loss 63.44374465942383\n",
      "inner_loss 63.437740325927734\n",
      "inner_loss 63.43187713623047\n",
      "inner_loss 63.42615509033203\n",
      "inner_loss 63.42057418823242\n",
      "inner_loss 63.41512680053711\n",
      "inner_loss 63.40981674194336\n",
      "inner_loss 63.40462875366211\n",
      "inner_loss 63.39957046508789\n",
      "inner_loss 63.394630432128906\n",
      "inner_loss 63.389808654785156\n",
      "inner_loss 63.38510513305664\n",
      "inner_loss 63.380516052246094\n",
      "inner_loss 63.37603759765625\n",
      "inner_loss 63.371665954589844\n",
      "inner_loss 63.36739730834961\n",
      "inner_loss 63.36323165893555\n",
      "inner_loss 63.359161376953125\n",
      "inner_loss 63.355194091796875\n",
      "inner_loss 63.351322174072266\n",
      "inner_loss 63.347537994384766\n",
      "inner_loss 63.34384536743164\n",
      "inner_loss 63.340240478515625\n",
      "inner_loss 63.33672332763672\n",
      "inner_loss 63.333290100097656\n",
      "inner_loss 63.32993698120117\n",
      "inner_loss 63.326663970947266\n",
      "inner_loss 63.32347106933594\n",
      "inner_loss 63.32034683227539\n",
      "inner_loss 63.317298889160156\n",
      "inner_loss 63.314327239990234\n",
      "inner_loss 63.31142044067383\n",
      "inner_loss 63.30858612060547\n",
      "inner_loss 63.30581283569336\n",
      "inner_loss 63.3031120300293\n",
      "inner_loss 63.300472259521484\n",
      "inner_loss 63.297889709472656\n",
      "inner_loss 63.295372009277344\n",
      "inner_loss 63.29291534423828\n",
      "inner_loss 63.2905158996582\n",
      "inner_loss 63.28816604614258\n",
      "inner_loss 63.2858772277832\n",
      "inner_loss 63.28363800048828\n",
      "inner_loss 63.28145217895508\n",
      "inner_loss 63.279319763183594\n",
      "inner_loss 63.2772331237793\n",
      "inner_loss 63.27519989013672\n",
      "inner_loss 63.27320861816406\n",
      "inner_loss 63.271263122558594\n",
      "inner_loss 63.26936721801758\n",
      "inner_loss 63.267513275146484\n",
      "inner_loss 63.26570129394531\n",
      "inner_loss 63.26393127441406\n",
      "inner_loss 63.262203216552734\n",
      "inner_loss 63.26051712036133\n",
      "inner_loss 63.25886535644531\n",
      "inner_loss 63.25725555419922\n",
      "inner_loss 63.255680084228516\n",
      "inner_loss 63.25414276123047\n",
      "inner_loss 63.25263977050781\n",
      "inner_loss 63.25117111206055\n",
      "inner_loss 63.249732971191406\n",
      "inner_loss 63.248329162597656\n",
      "inner_loss 63.2469596862793\n",
      "inner_loss 63.24562072753906\n",
      "inner_loss 63.24431228637695\n",
      "inner_loss 63.24303436279297\n",
      "inner_loss 63.241783142089844\n",
      "inner_loss 63.240562438964844\n",
      "inner_loss 63.23937225341797\n",
      "inner_loss 63.23820495605469\n",
      "inner_loss 63.237064361572266\n",
      "inner_loss 63.23594665527344\n",
      "inner_loss 63.23486328125\n",
      "inner_loss 63.233802795410156\n",
      "----------\n",
      "tensor(3.9198)\n",
      "tensor(3.9546)\n",
      "tensor(0.0684)\n",
      "tensor(1.0187)\n"
     ]
    }
   ],
   "source": [
    "with torch.enable_grad():\n",
    "\n",
    "    for j in range(inner_args['num_loops']):\n",
    "        loss = Mobj(H0, H1)\n",
    "        grads = autograd.grad(loss, Mobj.parameters(),\n",
    "                              create_graph=(not inner_args['detach']),\n",
    "                              only_inputs=True, allow_unused=True)\n",
    "        # parameter update\n",
    "        for param, grad in zip(Mobj.parameters(), grads):\n",
    "\n",
    "            #new_param = param - self.inner_args['lr'] * grad\n",
    "            new_param = param - 0.001 * grad\n",
    "\n",
    "            param.data.copy_(new_param)\n",
    "        if verbose: print(f\"\"\"inner_loss {loss.item()}\"\"\")\n",
    "    if verbose: print(\"-\"*10)\n",
    "Mstar = Mobj.Ms.data\n",
    "print(torch.max(torch.abs(H0)))\n",
    "print(torch.max(torch.abs(H1)))\n",
    "print(torch.max(torch.abs(grad)))\n",
    "print(torch.max(torch.abs(Mstar)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8794d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406d4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fee8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f32c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trueM = np.random.normal(size = (H0.shape[0], 16, 16))\n",
    "trueH1 = H0 @ trueM\n",
    "inner_args['num_loops']=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feec06c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8031373.0520, dtype=torch.float64)\n",
      "inner_loss 2832.312918718051\n",
      "inner_loss 2737.3636272374642\n",
      "inner_loss 2642.763533073331\n",
      "inner_loss 2548.5250797533727\n",
      "inner_loss 2454.661476738047\n",
      "inner_loss 2361.186762803141\n",
      "inner_loss 2268.1158796579502\n",
      "inner_loss 2175.4647600843173\n",
      "inner_loss 2083.2504214832456\n",
      "inner_loss 1991.4910725242457\n",
      "inner_loss 1900.2062380505674\n",
      "inner_loss 1809.416896398795\n",
      "inner_loss 1719.1456378249768\n",
      "inner_loss 1629.4168492704664\n",
      "inner_loss 1540.2569265213988\n",
      "inner_loss 1451.694514149948\n",
      "inner_loss 1363.7608021914873\n",
      "inner_loss 1276.4898585430024\n",
      "inner_loss 1189.91903328062\n",
      "inner_loss 1104.0894457175048\n",
      "inner_loss 1019.0465719021612\n",
      "inner_loss 934.8409574371425\n",
      "inner_loss 851.5291345096713\n",
      "inner_loss 769.1747515051326\n",
      "inner_loss 687.8500623646406\n",
      "inner_loss 607.6379070176282\n",
      "inner_loss 528.634430136876\n",
      "inner_loss 450.95303723087466\n",
      "inner_loss 374.73038794432\n",
      "inner_loss 300.1363551309704\n",
      "inner_loss 227.39247164796134\n",
      "inner_loss 156.81274314071018\n",
      "inner_loss 88.92811180073522\n",
      "inner_loss 25.454605847308873\n",
      "inner_loss 35.510316062925234\n",
      "inner_loss 30.009961242229714\n",
      "inner_loss 49.439258730284465\n",
      "inner_loss 52.5649224159754\n",
      "inner_loss 64.70724149145721\n",
      "inner_loss 56.80838300698939\n",
      "inner_loss 67.30605287756583\n",
      "inner_loss 58.64610092299625\n",
      "inner_loss 68.9034617397983\n",
      "inner_loss 59.81695401751931\n",
      "inner_loss 69.91704118298905\n",
      "inner_loss 60.559023527159745\n",
      "inner_loss 70.5608277211081\n",
      "inner_loss 61.034366333752764\n",
      "inner_loss 70.97841917536255\n",
      "inner_loss 61.348653001463084\n",
      "inner_loss 71.26037636161111\n",
      "inner_loss 61.56641912383016\n",
      "inner_loss 71.46069322873024\n",
      "inner_loss 61.725553771787524\n",
      "inner_loss 71.61088496344094\n",
      "inner_loss 61.848210081684556\n",
      "inner_loss 71.72951362135107\n",
      "inner_loss 61.94758372347212\n",
      "inner_loss 71.82777259331054\n",
      "inner_loss 62.03176284893094\n",
      "inner_loss 71.91260641625543\n",
      "inner_loss 62.10583351702023\n",
      "inner_loss 71.98845161646092\n",
      "inner_loss 62.1730882191721\n",
      "inner_loss 72.05818012170901\n",
      "inner_loss 62.23565893117692\n",
      "inner_loss 72.1236628599003\n",
      "inner_loss 62.294940066833924\n",
      "inner_loss 72.18611243166922\n",
      "inner_loss 62.35180973903814\n",
      "inner_loss 72.2462882669365\n",
      "inner_loss 62.40681236635865\n",
      "inner_loss 72.30463041236584\n",
      "inner_loss 62.460235586479435\n",
      "inner_loss 72.36135478931116\n",
      "inner_loss 62.51220348311879\n",
      "inner_loss 72.41651033745698\n",
      "inner_loss 62.56271733472278\n",
      "inner_loss 72.47006721061047\n",
      "inner_loss 62.61168117686176\n",
      "inner_loss 72.52189644882662\n",
      "inner_loss 62.65897434498228\n",
      "inner_loss 72.57185716674925\n",
      "inner_loss 62.704439045814915\n",
      "inner_loss 72.61975763840479\n",
      "inner_loss 62.74792906012606\n",
      "inner_loss 72.6654599534728\n",
      "inner_loss 62.78928764441743\n",
      "inner_loss 72.70880821250259\n",
      "inner_loss 62.828412194546374\n",
      "inner_loss 72.7496909149888\n",
      "inner_loss 62.865195465453134\n",
      "inner_loss 72.78803518917212\n",
      "inner_loss 62.89959830656599\n",
      "inner_loss 72.82379902214211\n",
      "inner_loss 62.93158778395627\n",
      "inner_loss 72.85697400462672\n",
      "inner_loss 62.96120049755746\n",
      "inner_loss 72.88759472098616\n",
      "inner_loss 62.988462100996934\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum((trueH1 - H0)**2))\n",
    "\n",
    "\n",
    "Mobj = mm.Meta_Mnet(dim_a=16, batchsize=32, mode='exact')\n",
    "Mobj.Ms.data = copy.deepcopy(problem['M'])\n",
    "with torch.enable_grad():\n",
    "\n",
    "    for j in range(inner_args['num_loops']):\n",
    "        loss = Mobj(H0, trueH1)\n",
    "        grads = autograd.grad(loss, Mobj.parameters(),\n",
    "                              create_graph=(not inner_args['detach']),\n",
    "                              only_inputs=True, allow_unused=True)\n",
    "        # parameter update\n",
    "        for param, grad in zip(Mobj.parameters(), grads):\n",
    "\n",
    "            #new_param = param - self.inner_args['lr'] * grad\n",
    "            new_param = param - 0.1 * grad\n",
    "\n",
    "            param.data.copy_(new_param)\n",
    "        if verbose: print(f\"\"\"inner_loss {loss.item()}\"\"\")\n",
    "    if verbose: print(\"-\"*10)\n",
    "Mstar = Mobj.Ms.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb50a003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.99521988, -1.56781337,  0.44956645, -0.7920913 ],\n",
       "       [ 0.55087646,  0.37448973, -0.70049339,  0.99912825],\n",
       "       [ 0.63325988,  0.73153545, -1.321742  ,  0.11886802],\n",
       "       [ 0.99759704,  1.34992008,  0.63435115, -0.5054478 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueM[0][:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595863ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9951, -1.5679,  0.4495, -0.7921],\n",
       "        [ 0.5509,  0.3745, -0.7005,  0.9991],\n",
       "        [ 0.6332,  0.7316, -1.3217,  0.1189],\n",
       "        [ 0.9978,  1.3498,  0.6343, -0.5055]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mobj.Ms[0][:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c04b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
