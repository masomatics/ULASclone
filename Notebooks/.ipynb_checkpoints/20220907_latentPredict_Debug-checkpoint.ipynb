{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f56fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs-mnj-hot-01/tmp/masomatics/block_diag/result/20220615_default_run_mnist\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['20220901_Mstar_inv_reg_cnn_0',\n",
       " '20220901_Mstar_orth_0',\n",
       " '20220906_latentPredict_0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../datasets')\n",
    "sys.path.append('../models')\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload\n",
    "from datasets.three_dim_shapes import ThreeDimShapesDataset\n",
    "from datasets.small_norb import SmallNORBDataset\n",
    "from datasets.seq_mnist import SequentialMNIST\n",
    "import models.seqae as seqae\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from datasets import so3_data as so3d\n",
    "from einops import rearrange\n",
    "from sklearn.metrics import r2_score\n",
    "import pdb\n",
    "from einops import rearrange\n",
    "from utils import evaluations as ev\n",
    "from utils import notebook_utils as nu\n",
    "\n",
    "import copy\n",
    "\n",
    "import csv\n",
    "import ast\n",
    "from source import yaml_utils as yu\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    gpu_index = -1\n",
    "\n",
    "\n",
    "    \n",
    "from utils import yaml_utils as yu\n",
    "import yaml\n",
    "rootpath = '/mnt/nfs-mnj-hot-01/tmp/masomatics/block_diag/'\n",
    "result_dir = '/mnt/nfs-mnj-hot-01/tmp/masomatics/block_diag/result'\n",
    "\n",
    "mode = 'so3'\n",
    "dat_root = f\"\"\"/mnt/nfs-mnj-hot-01/tmp/masomatics/block_diag/datasets/{mode}\"\"\"\n",
    "\n",
    "baseline_path = os.path.join(result_dir, '20220615_default_run_mnist')\n",
    "\n",
    "print(baseline_path)\n",
    "nu.filter_list('202209', os.listdir(result_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb05124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220906_latentPredict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['20220906_latentPredict_0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projname = 'latentPredict'\n",
    "setting_name = '_'.join(np.sort(nu.filter_list(projname, os.listdir(result_dir)))[0].split('_')[:-1])\n",
    "print(setting_name)\n",
    "nu.filter_list(projname, os.listdir(result_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce206ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../jobs/20220906_latentPredict\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['reg_latent005_reg_obs0_T3_predictiveTrue',\n",
       " 'reg_latent2_reg_obs0_T5_predictiveFalse',\n",
       " 'reg_latent2_reg_obs0_T3_predictiveTrue',\n",
       " 'reg_latent01_reg_obs0_T3_predictiveTrue',\n",
       " 'reg_latent01_reg_obs0_T5_predictiveFalse',\n",
       " 'reg_latent005_reg_obs0_T5_predictiveFalse',\n",
       " 'reg_latent1_reg_obs0_T3_predictiveTrue',\n",
       " 'reg_latent005_reg_obs0_T3_predictiveFalse',\n",
       " 'reg_latent01_reg_obs0_T3_predictiveFalse',\n",
       " 'reg_latent1_reg_obs0_T5_predictiveTrue',\n",
       " 'reg_latent01_reg_obs0_T5_predictiveTrue',\n",
       " 'reg_latent1_reg_obs0_T5_predictiveFalse',\n",
       " 'reg_latent2_reg_obs0_T5_predictiveTrue',\n",
       " 'reg_latent005_reg_obs0_T5_predictiveTrue',\n",
       " 'reg_latent2_reg_obs0_T3_predictiveFalse']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#projname = 'Mstar_orth_mlp_two' \n",
    "targdir = f'''20220906_{projname}_0'''\n",
    "#jobpath =f'''../jobs/20220829_{projname}'''\n",
    "jobpath = f'''../jobs/{setting_name}'''\n",
    "print(jobpath)\n",
    "print(os.path.exists(jobpath))\n",
    "#jobpath = os.path.join('../jobs/','_'.join(targdir.split('_')[:-1]))\n",
    "\n",
    "\n",
    "targpath = os.path.join(result_dir, targdir)\n",
    "targlist = os.listdir(targpath)\n",
    "\n",
    "targlist = nu.model_exists(targlist,  targpath)\n",
    "#print(targlist)\n",
    "\n",
    "nu.filter_list('reg_obs0', targlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307e7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkdir = 'reg_latent005_reg_obs0_T3_predictiveFalse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4065da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs-mnj-hot-01/tmp/masomatics/block_diag/result/20220906_latentPredict_0/reg_latent005_reg_obs0_T3_predictiveFalse \n",
      " snapshot_model_iter_100000\n"
     ]
    }
   ],
   "source": [
    "reload(ev)\n",
    "results = {} \n",
    "inferred_Ms = {} \n",
    "model_configs = {}\n",
    "models = {}\n",
    "tp = 1\n",
    "n_cond = 2\n",
    "device =  'cpu'\n",
    "\n",
    "Mlist = [] \n",
    "targdir_path = os.path.join(targpath, checkdir)\n",
    "\n",
    "config = nu.load_config(targdir_path)\n",
    "\n",
    "dataconfig = config['train_data']\n",
    "dataconfig['args']['T'] = tp + n_cond\n",
    "\n",
    "data = yu.load_component(dataconfig)\n",
    "train_loader = DataLoader(data, \n",
    "                          batch_size=config['batchsize'],\n",
    "                          shuffle=True,\n",
    "                          num_workers=config['num_workers'])\n",
    "\n",
    "model_config = config['model']\n",
    "model = yu.load_component(model_config)\n",
    "iterlist = nu.iter_list(targdir_path)\n",
    "\n",
    "maxiter = np.max(nu.iter_list(targdir_path))\n",
    "nu.load_model(model, targdir_path, maxiter)\n",
    "model = model.eval().to(device)\n",
    "\n",
    "images = iter(train_loader).next()\n",
    "\n",
    "# Initialize lazy modules\n",
    "if type(images) == list:\n",
    "    images = torch.stack(images)\n",
    "    images = images.transpose(1, 0)\n",
    "\n",
    "images = images.to(device)\n",
    "regconfig = config['reg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6bfe8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_cond = config['T_cond']\n",
    "#loss,  loss_dict = model.loss(images,  T_cond=T_cond, return_reg_loss=True, reconst=True, regconfig=regconfig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63cdc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rolls = images.shape[1] - T_cond\n",
    "H_preds, H_target, fn, M, H = model.compute_H_preds(images, n_rolls=n_rolls, T_cond=T_cond, reconst=True, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f92dee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10, 256, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054173c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
