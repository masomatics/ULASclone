{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "338cc434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch \n",
    "import torch.autograd as autograd\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "with open('H0H1.pkl', 'rb') as fp:\n",
    "    problem = pickle.load(fp)\n",
    "    \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models import misc_mnet as mm\n",
    "\n",
    "Mobj = mm.Meta_Mnet(dim_a=16, batchsize=32, mode='exact')\n",
    "Mobj.Ms.data = copy.deepcopy(problem['M'])\n",
    "\n",
    "inner_args= {}\n",
    "inner_args['num_loops'] = 200\n",
    "inner_args['detach'] = 1\n",
    "\n",
    "H0 = problem['H0']\n",
    "H1 = problem['H1']\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0244023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0280)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9665, -0.0133, -0.0074,  0.0030],\n",
       "        [-0.0232,  0.9505, -0.0124, -0.0154],\n",
       "        [-0.0015,  0.0166,  0.9546, -0.0024],\n",
       "        [ 0.0035, -0.0080,  0.0109,  0.9575]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.max(torch.abs(problem['M'])))\n",
    "\n",
    "\n",
    "Mobj.Ms[0][:4, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e398fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5017.1616, grad_fn=<SumBackward0>)\n",
      "tensor(5017.1616, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum((H1 - H0 @ Mobj.Ms)**2))\n",
    "print(Mobj(H0, H1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ead8761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inner_loss 70.83192443847656\n",
      "inner_loss 69.09257507324219\n",
      "inner_loss 67.72557830810547\n",
      "inner_loss 66.66382598876953\n",
      "inner_loss 65.84638214111328\n",
      "inner_loss 65.22077941894531\n",
      "inner_loss 64.74373626708984\n",
      "inner_loss 64.38057708740234\n",
      "inner_loss 64.10415649414062\n",
      "inner_loss 63.8935432434082\n",
      "inner_loss 63.73279571533203\n",
      "inner_loss 63.609806060791016\n",
      "inner_loss 63.51546096801758\n",
      "inner_loss 63.44286346435547\n",
      "inner_loss 63.386844635009766\n",
      "inner_loss 63.343475341796875\n",
      "inner_loss 63.3098030090332\n",
      "inner_loss 63.2835807800293\n",
      "inner_loss 63.26310348510742\n",
      "inner_loss 63.247066497802734\n",
      "inner_loss 63.23447036743164\n",
      "inner_loss 63.22456359863281\n",
      "inner_loss 63.21674346923828\n",
      "inner_loss 63.2105598449707\n",
      "inner_loss 63.205657958984375\n",
      "inner_loss 63.20176696777344\n",
      "inner_loss 63.198673248291016\n",
      "inner_loss 63.19620132446289\n",
      "inner_loss 63.19423294067383\n",
      "inner_loss 63.19266128540039\n",
      "inner_loss 63.1913948059082\n",
      "inner_loss 63.19038391113281\n",
      "inner_loss 63.189571380615234\n",
      "inner_loss 63.18891525268555\n",
      "inner_loss 63.18838882446289\n",
      "inner_loss 63.187965393066406\n",
      "inner_loss 63.187625885009766\n",
      "inner_loss 63.187347412109375\n",
      "inner_loss 63.1871223449707\n",
      "inner_loss 63.18694305419922\n",
      "inner_loss 63.18679428100586\n",
      "inner_loss 63.186676025390625\n",
      "inner_loss 63.186580657958984\n",
      "inner_loss 63.186500549316406\n",
      "inner_loss 63.18643569946289\n",
      "inner_loss 63.18638610839844\n",
      "inner_loss 63.18634033203125\n",
      "inner_loss 63.18630599975586\n",
      "inner_loss 63.186279296875\n",
      "inner_loss 63.18626022338867\n",
      "inner_loss 63.18623733520508\n",
      "inner_loss 63.186222076416016\n",
      "inner_loss 63.18621063232422\n",
      "inner_loss 63.18620300292969\n",
      "inner_loss 63.18619155883789\n",
      "inner_loss 63.18618392944336\n",
      "inner_loss 63.186180114746094\n",
      "inner_loss 63.18617630004883\n",
      "inner_loss 63.1861686706543\n",
      "inner_loss 63.1861686706543\n",
      "inner_loss 63.1861686706543\n",
      "inner_loss 63.18616485595703\n",
      "inner_loss 63.186161041259766\n",
      "inner_loss 63.186161041259766\n",
      "inner_loss 63.186161041259766\n",
      "inner_loss 63.186161041259766\n",
      "inner_loss 63.186161041259766\n",
      "inner_loss 63.186161041259766\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.1861572265625\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "inner_loss 63.186153411865234\n",
      "----------\n",
      "tensor(3.9198)\n",
      "tensor(3.9546)\n",
      "tensor(5.8983e-06)\n",
      "tensor(1.0196)\n"
     ]
    }
   ],
   "source": [
    "with torch.enable_grad():\n",
    "\n",
    "    for j in range(inner_args['num_loops']):\n",
    "        loss = torch.sqrt(Mobj(H0, H1))\n",
    "        grads = autograd.grad(loss, Mobj.parameters(),\n",
    "                              create_graph=(not inner_args['detach']),\n",
    "                              only_inputs=True, allow_unused=True)\n",
    "        # parameter update\n",
    "        for param, grad in zip(Mobj.parameters(), grads):\n",
    "\n",
    "            #new_param = param - self.inner_args['lr'] * grad\n",
    "            new_param = param - 0.01 * grad\n",
    "\n",
    "            param.data.copy_(new_param)\n",
    "        if verbose: print(f\"\"\"inner_loss {loss.item()}\"\"\")\n",
    "    if verbose: print(\"-\"*10)\n",
    "Mstar = Mobj.Ms.data\n",
    "print(torch.max(torch.abs(H0)))\n",
    "print(torch.max(torch.abs(H1)))\n",
    "print(torch.max(torch.abs(grad)))\n",
    "print(torch.max(torch.abs(Mstar)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a129ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0c7f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338396ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "94f3bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trueM = np.random.normal(size = (H0.shape[0], 16, 16))\n",
    "trueH1 = H0 @ trueM\n",
    "inner_args['num_loops']=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "139d309d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8035240.5132, dtype=torch.float64)\n",
      "inner_loss 3.8553474594269765\n",
      "inner_loss 9.784412211710457\n",
      "inner_loss 3.855344032849357\n",
      "inner_loss 9.784413850868386\n",
      "inner_loss 3.8553444983755116\n",
      "inner_loss 9.784413310828185\n",
      "inner_loss 3.855345644172447\n",
      "inner_loss 9.784412364940856\n",
      "inner_loss 3.8553461124780317\n",
      "inner_loss 9.784412222779215\n",
      "inner_loss 3.855346718982437\n",
      "inner_loss 9.78441372064462\n",
      "inner_loss 3.855345385266942\n",
      "inner_loss 9.784413150568188\n",
      "inner_loss 3.8553460367747845\n",
      "inner_loss 9.784414378326051\n",
      "inner_loss 3.855345184048951\n",
      "inner_loss 9.784412181032886\n",
      "inner_loss 3.855345380789311\n",
      "inner_loss 9.784413336663514\n",
      "inner_loss 3.855345981285443\n",
      "inner_loss 9.784410992996193\n",
      "inner_loss 3.8553467367368395\n",
      "inner_loss 9.784412853797177\n",
      "inner_loss 3.8553461217682683\n",
      "inner_loss 9.784410539497216\n",
      "inner_loss 3.855346924542561\n",
      "inner_loss 9.784411265427671\n",
      "inner_loss 3.855348280894171\n",
      "inner_loss 9.784411619045787\n",
      "inner_loss 3.8553477168046255\n",
      "inner_loss 9.78441129097589\n",
      "inner_loss 3.855346256400944\n",
      "inner_loss 9.784414356199644\n",
      "inner_loss 3.8553429703711495\n",
      "inner_loss 9.78441690478459\n",
      "inner_loss 3.8553430528184\n",
      "inner_loss 9.784417116519032\n",
      "inner_loss 3.8553420841298727\n",
      "inner_loss 9.784417439704637\n",
      "inner_loss 3.8553406324748916\n",
      "inner_loss 9.78441755685282\n",
      "inner_loss 3.8553418449481\n",
      "inner_loss 9.784417785182056\n",
      "inner_loss 3.8553410432506436\n",
      "inner_loss 9.78441915158971\n",
      "inner_loss 3.8553409049540686\n",
      "inner_loss 9.78441733294614\n",
      "inner_loss 3.855341581612531\n",
      "inner_loss 9.784417040204833\n",
      "inner_loss 3.855344251816533\n",
      "inner_loss 9.784415527144512\n",
      "inner_loss 3.8553426714507983\n",
      "inner_loss 9.78441385229701\n",
      "inner_loss 3.855344223342206\n",
      "inner_loss 9.784416215395222\n",
      "inner_loss 3.8553414079774138\n",
      "inner_loss 9.784417201877618\n",
      "inner_loss 3.8553429922243785\n",
      "inner_loss 9.784414670417874\n",
      "inner_loss 3.855341998589443\n",
      "inner_loss 9.78441597501002\n",
      "inner_loss 3.8553421762484086\n",
      "inner_loss 9.784414825254915\n",
      "inner_loss 3.855343158133502\n",
      "inner_loss 9.784415327637129\n",
      "inner_loss 3.8553443523681166\n",
      "inner_loss 9.784414808708334\n",
      "inner_loss 3.8553447615117853\n",
      "inner_loss 9.78441198195511\n",
      "inner_loss 3.855345052316318\n",
      "inner_loss 9.784415292965752\n",
      "inner_loss 3.8553449024391115\n",
      "inner_loss 9.7844157207361\n",
      "inner_loss 3.855343993256199\n",
      "inner_loss 9.784416144803933\n",
      "inner_loss 3.855345323740129\n",
      "inner_loss 9.784414660360529\n",
      "inner_loss 3.8553455181059566\n",
      "inner_loss 9.784414340384917\n",
      "inner_loss 3.8553463890295365\n",
      "inner_loss 9.784413740053084\n",
      "inner_loss 3.8553462943373398\n",
      "inner_loss 9.784414020441906\n",
      "inner_loss 3.8553454678288337\n",
      "inner_loss 9.784416118655972\n",
      "inner_loss 3.855343186877946\n",
      "inner_loss 9.784415581981792\n",
      "inner_loss 3.8553428746810527\n",
      "inner_loss 9.784416650638349\n",
      "inner_loss 3.8553434299150937\n",
      "inner_loss 9.784414847402916\n",
      "inner_loss 3.8553454784781622\n",
      "inner_loss 9.78441449348167\n",
      "inner_loss 3.8553462967524785\n",
      "inner_loss 9.784415748796018\n",
      "inner_loss 3.855344577396195\n",
      "inner_loss 9.784415087146265\n",
      "inner_loss 3.8553450105961744\n",
      "inner_loss 9.78441541367952\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum((trueH1 - H0)**2))\n",
    "\n",
    "\n",
    "Mobj = mm.Meta_Mnet(dim_a=16, batchsize=32, mode='exact')\n",
    "Mobj.Ms.data = problem['M']\n",
    "with torch.enable_grad():\n",
    "\n",
    "    for j in range(inner_args['num_loops']):\n",
    "        loss = torch.sqrt(Mobj(H0, trueH1))\n",
    "        grads = autograd.grad(loss, Mobj.parameters(),\n",
    "                              create_graph=(not inner_args['detach']),\n",
    "                              only_inputs=True, allow_unused=True)\n",
    "        # parameter update\n",
    "        for param, grad in zip(Mobj.parameters(), grads):\n",
    "\n",
    "            #new_param = param - self.inner_args['lr'] * grad\n",
    "            new_param = param - 0.01 * grad\n",
    "\n",
    "            param.data.copy_(new_param)\n",
    "        if verbose: print(f\"\"\"inner_loss {loss.item()}\"\"\")\n",
    "    if verbose: print(\"-\"*10)\n",
    "Mstar = Mobj.Ms.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ce8287e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.6650e-01, -1.3283e-02, -7.3722e-03,  ..., -1.8794e-02,\n",
       "          -8.9796e-03, -5.0603e-03],\n",
       "         [-2.3249e-02,  9.5054e-01, -1.2418e-02,  ...,  3.6499e-03,\n",
       "           7.3203e-04,  8.9612e-03],\n",
       "         [-1.4642e-03,  1.6566e-02,  9.5465e-01,  ..., -1.0844e-02,\n",
       "           1.0966e-02,  1.4862e-02],\n",
       "         ...,\n",
       "         [-1.1227e-02, -8.5670e-03,  5.1696e-04,  ...,  9.6276e-01,\n",
       "           1.4004e-02, -6.0834e-03],\n",
       "         [-2.2733e-03, -2.4646e-02, -1.2577e-03,  ...,  5.4033e-03,\n",
       "           9.5847e-01, -9.1117e-04],\n",
       "         [ 6.1454e-03,  5.0446e-03, -4.3451e-03,  ...,  9.1514e-03,\n",
       "          -6.7387e-03,  9.6855e-01]],\n",
       "\n",
       "        [[ 9.6499e-01,  1.9607e-03,  1.7975e-02,  ..., -3.7439e-03,\n",
       "          -6.6518e-03, -1.6288e-02],\n",
       "         [ 1.6901e-02,  9.7282e-01,  5.8241e-03,  ..., -5.2050e-04,\n",
       "          -1.4098e-02,  3.7857e-03],\n",
       "         [-7.6398e-03,  1.3109e-02,  9.7694e-01,  ..., -3.3054e-02,\n",
       "           1.5976e-02, -9.7068e-03],\n",
       "         ...,\n",
       "         [ 3.4206e-03, -1.5002e-02, -1.2759e-02,  ...,  9.8265e-01,\n",
       "           3.3966e-03,  1.0113e-02],\n",
       "         [-1.6387e-04, -1.0055e-03,  8.6931e-03,  ..., -3.2642e-03,\n",
       "           1.0013e+00,  1.0018e-02],\n",
       "         [ 4.8348e-03,  7.2200e-04,  2.7111e-03,  ..., -2.5319e-03,\n",
       "          -4.4196e-03,  9.5895e-01]],\n",
       "\n",
       "        [[ 9.8942e-01,  6.1232e-03, -3.9188e-04,  ..., -1.3716e-02,\n",
       "          -3.9148e-03, -2.6110e-03],\n",
       "         [ 1.8588e-02,  9.5825e-01, -3.4010e-03,  ...,  3.4547e-03,\n",
       "           1.1538e-02, -2.6410e-02],\n",
       "         [ 6.1757e-03, -3.6294e-02,  9.5480e-01,  ...,  9.9015e-03,\n",
       "           1.4540e-02,  1.0202e-02],\n",
       "         ...,\n",
       "         [-6.2647e-03,  1.2132e-02, -4.7088e-04,  ...,  9.7917e-01,\n",
       "          -1.4764e-03,  1.0061e-02],\n",
       "         [-1.7440e-02, -9.1681e-03, -1.7222e-02,  ..., -1.8822e-02,\n",
       "           9.7023e-01,  1.4627e-02],\n",
       "         [-3.0285e-03, -1.8070e-02, -5.6230e-03,  ...,  1.4866e-03,\n",
       "           2.5140e-02,  9.7682e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9.8007e-01,  9.9180e-03, -7.3946e-03,  ...,  7.1496e-03,\n",
       "          -6.4993e-03, -3.7898e-03],\n",
       "         [ 1.0575e-02,  9.9496e-01, -2.8569e-03,  ..., -1.9781e-02,\n",
       "          -1.9654e-03, -3.6868e-06],\n",
       "         [-2.2939e-04,  3.0993e-03,  9.9972e-01,  ..., -4.8515e-03,\n",
       "           1.9674e-03,  9.6837e-03],\n",
       "         ...,\n",
       "         [ 2.4472e-03, -2.9170e-03,  4.5763e-03,  ...,  9.9674e-01,\n",
       "           1.4038e-02,  1.7165e-02],\n",
       "         [-1.8121e-03, -1.6928e-02,  7.2693e-03,  ..., -4.4180e-03,\n",
       "           9.9182e-01,  3.3290e-03],\n",
       "         [ 1.2865e-03,  5.4368e-03,  5.2366e-03,  ..., -1.1022e-03,\n",
       "          -1.4205e-02,  9.9633e-01]],\n",
       "\n",
       "        [[ 1.0053e+00, -5.7575e-03,  7.3133e-03,  ..., -3.3446e-03,\n",
       "           1.1907e-03, -8.9945e-03],\n",
       "         [ 1.4754e-03,  1.0022e+00,  4.7902e-03,  ..., -1.4899e-02,\n",
       "          -9.7632e-03, -1.2420e-02],\n",
       "         [ 6.1766e-03, -1.2565e-03,  9.9929e-01,  ...,  2.9231e-03,\n",
       "          -3.1925e-03, -5.7406e-03],\n",
       "         ...,\n",
       "         [ 5.1707e-03,  1.5211e-03, -1.5487e-03,  ...,  9.9746e-01,\n",
       "           7.8160e-03, -1.1264e-03],\n",
       "         [-6.8930e-03,  9.0459e-05, -4.6391e-03,  ..., -6.0575e-03,\n",
       "           9.9909e-01,  8.7229e-03],\n",
       "         [ 2.7977e-03,  1.8974e-03,  5.6464e-03,  ..., -3.3772e-03,\n",
       "           9.9753e-03,  1.0048e+00]],\n",
       "\n",
       "        [[ 9.6768e-01,  1.1250e-02, -2.9492e-03,  ...,  3.1185e-02,\n",
       "          -3.5280e-03,  7.0029e-03],\n",
       "         [-1.0245e-02,  9.6539e-01,  8.0005e-03,  ...,  5.7415e-03,\n",
       "           7.8455e-03,  7.6949e-03],\n",
       "         [-1.4824e-03,  4.3971e-03,  9.8383e-01,  ..., -9.9429e-03,\n",
       "          -1.2590e-03,  7.3053e-03],\n",
       "         ...,\n",
       "         [ 6.1053e-03,  1.3064e-02,  1.7207e-03,  ...,  9.6527e-01,\n",
       "          -7.1209e-03,  1.3659e-02],\n",
       "         [ 7.4153e-03,  9.9392e-03,  4.9236e-03,  ..., -1.8804e-03,\n",
       "           9.9389e-01,  1.1378e-02],\n",
       "         [ 7.6229e-03, -6.4988e-03,  3.7858e-03,  ..., -1.0691e-02,\n",
       "           6.7991e-03,  9.6949e-01]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem['M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315c4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
