{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49d21887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../datasets')\n",
    "sys.path.append('../models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload\n",
    "from datasets.three_dim_shapes import ThreeDimShapesDataset\n",
    "from datasets.small_norb import SmallNORBDataset\n",
    "from datasets.seq_mnist import SequentialMNIST\n",
    "import models.seqae as seqae\n",
    "from einops import rearrange\n",
    "import signal\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    gpu_index = -1\n",
    "\n",
    "import yaml\n",
    "from source import yaml_utils as yu\n",
    "\n",
    "\n",
    "def contain(queries, mystr, mode='any'):\n",
    "    if mode == 'any':\n",
    "        containment = False\n",
    "        for key in queries:\n",
    "            if key in mystr:\n",
    "                containment = True\n",
    "    elif mode == 'all':\n",
    "        containment = True\n",
    "        for key in queries:\n",
    "            if key not in mystr:\n",
    "                containment = False\n",
    "    return containment\n",
    "\n",
    "def filterdir(queries, dirlist, mode ='any'):\n",
    "    mylist = []\n",
    "    for dirname in dirlist:\n",
    "        containment = contain(queries, dirname, mode=mode)\n",
    "        if containment == True:\n",
    "            mylist = mylist + [dirname]\n",
    "    return mylist\n",
    "\n",
    "def filter_dict(queries, mydict, mode = 'any'):\n",
    "    outdict = {} \n",
    "    for dirname in mydict.keys():\n",
    "        containment = contain(queries, dirname, mode=mode)\n",
    "        if containment == True:\n",
    "            outdict[dirname] = mydict[dirname]\n",
    "    return outdict\n",
    "\n",
    "result_dir = '/mnt/nfs-mnj-hot-01/tmp/masomatics/block_diag/result'\n",
    "dirlist = os.listdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5626357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20220701_so3_various_dat_two_0']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterdir(['20220701'], dirlist, mode='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "682364c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "targdir = '20220701_so3_various_dat_two_0'\n",
    "exp_result_dir = os.path.join(result_dir, targdir)\n",
    "result_list = os.listdir(exp_result_dir)\n",
    "\n",
    "\n",
    "def obtain_info(dirpath):\n",
    "    targ_config_path = os.path.join(dirpath, 'config.yml')\n",
    "    targ_log_path = os.path.join(dirpath, 'log')\n",
    "    if os.path.exists(targ_log_path) != True or os.path.exists(targ_config_path) != True:\n",
    "        print(f\"\"\"{targ_log_path} or {targ_config_path} does not exist \"\"\")\n",
    "        return None \n",
    "    with open(targ_config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        \n",
    "    with open(targ_log_path) as f:\n",
    "        log = yaml.safe_load(f)\n",
    "    return config, log\n",
    "\n",
    "def load_model(model, model_dir, iters):\n",
    "    model_path = os.path.join(\n",
    "        model_dir, 'snapshot_model_iter_{}'.format(iters))\n",
    "\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\"\"{model_path} does not exist\"\"\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f64731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "/usr/local/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "allresults = {} \n",
    "allconfigs = {}\n",
    "alllogs = {} \n",
    "for mydir in result_list:\n",
    "\n",
    "    dirpath = os.path.join(exp_result_dir, mydir)\n",
    "    config, log = obtain_info(dirpath)\n",
    "\n",
    "    data = yu.load_component(config['train_data'])\n",
    "\n",
    "    train_loader = DataLoader(data, \n",
    "                              batch_size=config['batchsize'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=config['num_workers'])\n",
    "    model = yu.load_component(config['model'])\n",
    "    load_model(model, dirpath, config['max_iteration'])\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    scores = [] \n",
    "    for idx, dat in enumerate(train_loader):\n",
    "        dat = rearrange(dat, 'b t a -> (b t) a' ).to(device)\n",
    "        d0hat =  model.dec(model.enc(dat)).detach().to(device)\n",
    "\n",
    "        scores.append(seqae.r2_score(d0hat.to('cpu'), dat.to('cpu')))\n",
    "\n",
    "    scores = torch.tensor(scores)\n",
    "    allresults[mydir] = torch.mean(scores)\n",
    "    allconfigs[mydir] = config\n",
    "    alllogs[mydir] = log\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1ca46076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr0001_data_filenameso3dat_sphere_MLPpt_nameSeqAELSTSQ_LinearNet': tensor(-0.8075, dtype=torch.float64),\n",
       " 'lr0001_data_filenameso3dat_sphere_Linearpt_nameSeqAELSTSQ_LinearNet': tensor(0.9996, dtype=torch.float64),\n",
       " 'lr0001_data_filenameso3dat_sphere_iResNetpt_nameSeqAELSTSQ_LinearNet': tensor(0.9998, dtype=torch.float64)}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dict(['Q_LinearNet', 'lr0001'], allresults, mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75e33d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr0001_data_filenameso3dat_sphere_iResNetpt_nameSeqAELSTSQ_so3Net': tensor(0.4926, dtype=torch.float64),\n",
       " 'lr0001_data_filenameso3dat_sphere_MLPpt_nameSeqAELSTSQ_so3Net': tensor(-6.2020e+08, dtype=torch.float64),\n",
       " 'lr0001_data_filenameso3dat_sphere_Linearpt_nameSeqAELSTSQ_so3Net': tensor(0.8089, dtype=torch.float64)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dict(['Q_so3Net', 'lr0001'], allresults, mode='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2702c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylogs = filter_dict(['Q_so3Net', 'lr00001', 'MLPpt'], alllogs, mode='all')\n",
    "mylog = mylogs[list(mylogs.keys())[0]]\n",
    "\n",
    "check_label = 'train/loss'\n",
    "curve = [mylog[k][check_label] for k in range(len(mylog))]\n",
    "iters = [mylog[k]['iteration'] for k in range(len(mylog))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbf474df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f09d7e3a280>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters, curve,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction loss\n",
    "\n",
    "tp=5\n",
    "\n",
    "pred_results = {}\n",
    "\n",
    "\n",
    "data = yu.load_component(config['train_data'])\n",
    "\n",
    "\n",
    "#This part must be changed later \n",
    "test_loader = DataLoader(data, \n",
    "                          batch_size=config['batchsize'],\n",
    "                          shuffle=True,\n",
    "                          num_workers=config['num_workers'])\n",
    "model = yu.load_component(config['model'])\n",
    "load_model(model, dirpath, config['max_iteration'])\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "exists = load_model(model, dirpath, iters=iters)\n",
    "if exists == True: \n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize lazy modules\n",
    "    images = iter(test_loader).next()\n",
    "    images = torch.stack(images).transpose(1, 0)\n",
    "    images = images.to(device)\n",
    "    model(images[:, :2])\n",
    "    \n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        scores = []\n",
    "        for images in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            images_cond = images[:, :n_cond]\n",
    "            images_target = images[:, n_cond:n_cond+tp]\n",
    "            M = model.get_M(images_cond) #n a a\n",
    "            H = model.encode(images_cond[:, -1:])[:, 0] # n s a\n",
    "            \n",
    "            xs = []\n",
    "            for r in range(tp):\n",
    "\n",
    "                H1 = H1 @ M \n",
    "                x_next_t = model.decode(H1[:, None])\n",
    "                xs.append(x_next_t)\n",
    "\n",
    "            x_next = torch.cat(xs, axis=1)\n",
    "\n",
    "            r2_loss = r2_score(images_target, x_next) \n",
    "            scores.append(r2_loss)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49b57b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
